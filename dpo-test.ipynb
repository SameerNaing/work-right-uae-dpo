{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "44ad71b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "from unsloth import FastLanguageModel\n",
    "import torch\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "096a6054",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==((====))==  Unsloth 2025.9.1: Fast Gemma3 patching. Transformers: 4.56.1.\n",
      "   \\\\   /|    NVIDIA GeForce RTX 3080 Ti. Num GPUs = 1. Max memory: 11.631 GB. Platform: Linux.\n",
      "O^O/ \\_/ \\    Torch: 2.8.0+cu128. CUDA: 8.6. CUDA Toolkit: 12.8. Triton: 3.4.0\n",
      "\\        /    Bfloat16 = TRUE. FA [Xformers = 0.0.32.post2. FA2 = False]\n",
      " \"-____-\"     Free license: http://github.com/unslothai/unsloth\n",
      "Unsloth: Fast downloading is enabled - ignore downloading bars which are red colored!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fetching 2 files: 100%|██████████| 2/2 [00:01<00:00,  1.77it/s]\n"
     ]
    }
   ],
   "source": [
    "model_name = \"google/gemma-3-4b-it\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "model, _ = FastLanguageModel.from_pretrained(\n",
    "    model_name=model_name, \n",
    "    max_seq_length=8192, \n",
    "    dtype=None,\n",
    "    load_in_4bit = True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0db1a2e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Gemma3ForConditionalGeneration(\n",
       "  (model): Gemma3Model(\n",
       "    (vision_tower): SiglipVisionModel(\n",
       "      (vision_model): SiglipVisionTransformer(\n",
       "        (embeddings): SiglipVisionEmbeddings(\n",
       "          (patch_embedding): Conv2d(3, 1152, kernel_size=(14, 14), stride=(14, 14), padding=valid)\n",
       "          (position_embedding): Embedding(4096, 1152)\n",
       "        )\n",
       "        (encoder): SiglipEncoder(\n",
       "          (layers): ModuleList(\n",
       "            (0-26): 27 x SiglipEncoderLayer(\n",
       "              (layer_norm1): LayerNorm((1152,), eps=1e-06, elementwise_affine=True)\n",
       "              (self_attn): SiglipAttention(\n",
       "                (k_proj): Linear(in_features=1152, out_features=1152, bias=True)\n",
       "                (v_proj): Linear(in_features=1152, out_features=1152, bias=True)\n",
       "                (q_proj): Linear(in_features=1152, out_features=1152, bias=True)\n",
       "                (out_proj): Linear(in_features=1152, out_features=1152, bias=True)\n",
       "              )\n",
       "              (layer_norm2): LayerNorm((1152,), eps=1e-06, elementwise_affine=True)\n",
       "              (mlp): SiglipMLP(\n",
       "                (activation_fn): PytorchGELUTanh()\n",
       "                (fc1): Linear(in_features=1152, out_features=4304, bias=True)\n",
       "                (fc2): Linear(in_features=4304, out_features=1152, bias=True)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (post_layernorm): LayerNorm((1152,), eps=1e-06, elementwise_affine=True)\n",
       "      )\n",
       "    )\n",
       "    (multi_modal_projector): Gemma3MultiModalProjector(\n",
       "      (mm_soft_emb_norm): Gemma3RMSNorm((1152,), eps=1e-06)\n",
       "      (avg_pool): AvgPool2d(kernel_size=4, stride=4, padding=0)\n",
       "    )\n",
       "    (language_model): Gemma3TextModel(\n",
       "      (embed_tokens): Gemma3TextScaledWordEmbedding(262208, 2560, padding_idx=0)\n",
       "      (layers): ModuleList(\n",
       "        (0-1): 2 x Gemma3DecoderLayer(\n",
       "          (self_attn): Gemma3Attention(\n",
       "            (q_proj): Linear4bit(in_features=2560, out_features=2048, bias=False)\n",
       "            (k_proj): Linear4bit(in_features=2560, out_features=1024, bias=False)\n",
       "            (v_proj): Linear4bit(in_features=2560, out_features=1024, bias=False)\n",
       "            (o_proj): Linear4bit(in_features=2048, out_features=2560, bias=False)\n",
       "            (q_norm): Gemma3RMSNorm((256,), eps=1e-06)\n",
       "            (k_norm): Gemma3RMSNorm((256,), eps=1e-06)\n",
       "          )\n",
       "          (mlp): Gemma3MLP(\n",
       "            (gate_proj): Linear(in_features=2560, out_features=10240, bias=False)\n",
       "            (up_proj): Linear(in_features=2560, out_features=10240, bias=False)\n",
       "            (down_proj): Linear(in_features=10240, out_features=2560, bias=False)\n",
       "            (act_fn): PytorchGELUTanh()\n",
       "          )\n",
       "          (input_layernorm): Gemma3RMSNorm((2560,), eps=1e-06)\n",
       "          (post_attention_layernorm): Gemma3RMSNorm((2560,), eps=1e-06)\n",
       "          (pre_feedforward_layernorm): Gemma3RMSNorm((2560,), eps=1e-06)\n",
       "          (post_feedforward_layernorm): Gemma3RMSNorm((2560,), eps=1e-06)\n",
       "        )\n",
       "        (2): Gemma3DecoderLayer(\n",
       "          (self_attn): Gemma3Attention(\n",
       "            (q_proj): Linear(in_features=2560, out_features=2048, bias=False)\n",
       "            (k_proj): Linear(in_features=2560, out_features=1024, bias=False)\n",
       "            (v_proj): Linear(in_features=2560, out_features=1024, bias=False)\n",
       "            (o_proj): Linear(in_features=2048, out_features=2560, bias=False)\n",
       "            (q_norm): Gemma3RMSNorm((256,), eps=1e-06)\n",
       "            (k_norm): Gemma3RMSNorm((256,), eps=1e-06)\n",
       "          )\n",
       "          (mlp): Gemma3MLP(\n",
       "            (gate_proj): Linear(in_features=2560, out_features=10240, bias=False)\n",
       "            (up_proj): Linear(in_features=2560, out_features=10240, bias=False)\n",
       "            (down_proj): Linear(in_features=10240, out_features=2560, bias=False)\n",
       "            (act_fn): PytorchGELUTanh()\n",
       "          )\n",
       "          (input_layernorm): Gemma3RMSNorm((2560,), eps=1e-06)\n",
       "          (post_attention_layernorm): Gemma3RMSNorm((2560,), eps=1e-06)\n",
       "          (pre_feedforward_layernorm): Gemma3RMSNorm((2560,), eps=1e-06)\n",
       "          (post_feedforward_layernorm): Gemma3RMSNorm((2560,), eps=1e-06)\n",
       "        )\n",
       "        (3-5): 3 x Gemma3DecoderLayer(\n",
       "          (self_attn): Gemma3Attention(\n",
       "            (q_proj): Linear4bit(in_features=2560, out_features=2048, bias=False)\n",
       "            (k_proj): Linear4bit(in_features=2560, out_features=1024, bias=False)\n",
       "            (v_proj): Linear4bit(in_features=2560, out_features=1024, bias=False)\n",
       "            (o_proj): Linear4bit(in_features=2048, out_features=2560, bias=False)\n",
       "            (q_norm): Gemma3RMSNorm((256,), eps=1e-06)\n",
       "            (k_norm): Gemma3RMSNorm((256,), eps=1e-06)\n",
       "          )\n",
       "          (mlp): Gemma3MLP(\n",
       "            (gate_proj): Linear(in_features=2560, out_features=10240, bias=False)\n",
       "            (up_proj): Linear(in_features=2560, out_features=10240, bias=False)\n",
       "            (down_proj): Linear(in_features=10240, out_features=2560, bias=False)\n",
       "            (act_fn): PytorchGELUTanh()\n",
       "          )\n",
       "          (input_layernorm): Gemma3RMSNorm((2560,), eps=1e-06)\n",
       "          (post_attention_layernorm): Gemma3RMSNorm((2560,), eps=1e-06)\n",
       "          (pre_feedforward_layernorm): Gemma3RMSNorm((2560,), eps=1e-06)\n",
       "          (post_feedforward_layernorm): Gemma3RMSNorm((2560,), eps=1e-06)\n",
       "        )\n",
       "        (6-33): 28 x Gemma3DecoderLayer(\n",
       "          (self_attn): Gemma3Attention(\n",
       "            (q_proj): Linear4bit(in_features=2560, out_features=2048, bias=False)\n",
       "            (k_proj): Linear4bit(in_features=2560, out_features=1024, bias=False)\n",
       "            (v_proj): Linear4bit(in_features=2560, out_features=1024, bias=False)\n",
       "            (o_proj): Linear4bit(in_features=2048, out_features=2560, bias=False)\n",
       "            (q_norm): Gemma3RMSNorm((256,), eps=1e-06)\n",
       "            (k_norm): Gemma3RMSNorm((256,), eps=1e-06)\n",
       "          )\n",
       "          (mlp): Gemma3MLP(\n",
       "            (gate_proj): Linear4bit(in_features=2560, out_features=10240, bias=False)\n",
       "            (up_proj): Linear4bit(in_features=2560, out_features=10240, bias=False)\n",
       "            (down_proj): Linear4bit(in_features=10240, out_features=2560, bias=False)\n",
       "            (act_fn): PytorchGELUTanh()\n",
       "          )\n",
       "          (input_layernorm): Gemma3RMSNorm((2560,), eps=1e-06)\n",
       "          (post_attention_layernorm): Gemma3RMSNorm((2560,), eps=1e-06)\n",
       "          (pre_feedforward_layernorm): Gemma3RMSNorm((2560,), eps=1e-06)\n",
       "          (post_feedforward_layernorm): Gemma3RMSNorm((2560,), eps=1e-06)\n",
       "        )\n",
       "      )\n",
       "      (norm): Gemma3RMSNorm((2560,), eps=1e-06)\n",
       "      (rotary_emb): Gemma3RotaryEmbedding()\n",
       "      (rotary_emb_local): Gemma3RotaryEmbedding()\n",
       "    )\n",
       "  )\n",
       "  (lm_head): Linear(in_features=2560, out_features=262208, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "FastLanguageModel.for_inference(model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3adeeded",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = tokenizer.encode(\"My name is Naing Ye Oo.\", return_tensors=\"pt\", add_special_tokens=False)\n",
    "bad_res = tokenizer.encode(\"Hello Naing Ye Oo.\", return_tensors=\"pt\", add_special_tokens=False)\n",
    "good_res = tokenizer.encode(\"Hello Naing Ye Oo, How can I help you today ?\", return_tensors=\"pt\", add_special_tokens=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "20b752e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "good_ids = torch.cat([prompt, good_res], dim=1)\n",
    "bad_ids  = torch.cat([prompt, bad_res],  dim=1)\n",
    "good_attn = torch.ones_like(good_ids)\n",
    "bad_attn  = torch.ones_like(bad_ids)\n",
    "\n",
    "good_labels = good_ids.clone()\n",
    "bad_labels  = bad_ids.clone()\n",
    "good_labels[:, :prompt.size(1)] = -100\n",
    "bad_labels[:,  :prompt.size(1)] = -100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "fae0641f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def seq_logprob(model, input_ids, attention_mask, labels):\n",
    "    with torch.no_grad() if not model.training else torch.enable_grad():\n",
    "        out = model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "    logits = out.logits \n",
    "\n",
    "    logits = logits[:, :-1, :]\n",
    "    target = labels[:, 1:]                    \n",
    "    mask   = (target != -100).to(logits.dtype) \n",
    "\n",
    "    logp_tok = F.log_softmax(logits, dim=-1)\n",
    "    tgt_logp = logp_tok.gather(-1, target.unsqueeze(-1).clamp_min(0)).squeeze(-1)\n",
    "\n",
    "    # sum only over response tokens\n",
    "    return (tgt_logp * mask).sum(dim=1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b3d6334",
   "metadata": {},
   "outputs": [],
   "source": [
    "logp_pol_good = seq_logprob(model, good_ids.to(\"cuda\"), good_attn.to(\"cuda\"), good_labels.to(\"cuda\"))    # log πθ(y+|x)\n",
    "# logp_pol_bad  = seq_logprob(model, bad_ids.to(\"cuda\"),  bad_attn.to(\"cuda\"),  bad_labels.to(\"cuda\")) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "b932abda",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-67.], device='cuda:0', dtype=torch.bfloat16)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logp_pol_good"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "cfe6c8c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 13, 262208])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logists[:, :-1, : ].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "102a7f8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logits shape: torch.Size([1, 3, 5])\n",
      "target: tensor([[4, 0, 2]])\n",
      "target_unsq shape: torch.Size([1, 3, 1])\n",
      "tgt_logp shape gather: torch.Size([1, 3, 1])\n",
      "tgt_logp gather: tensor([[[-0.4519],\n",
      "         [-0.4519],\n",
      "         [-2.4519]]])\n",
      "tgt_logp shape after squeeze: torch.Size([1, 3])\n",
      "tgt_logp values: tensor([[-0.4519, -0.4519, -2.4519]])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# fake logits (batch=1, seq=3, vocab=5)\n",
    "logits = torch.tensor([[\n",
    "    [1.0, 2.0, 3.0, 4.0, 5.0],   # timestep 0\n",
    "    [5.0, 4.0, 3.0, 2.0, 1.0],   # timestep 1\n",
    "    [0.5, 1.5, 2.5, 3.5, 4.5]    # timestep 2\n",
    "]])\n",
    "\n",
    "print(\"logits shape:\", logits.shape)  # [1, 3, 5]\n",
    "\n",
    "# convert to log-probs\n",
    "logp_tok = F.log_softmax(logits, dim=-1)\n",
    "\n",
    "# pretend target tokens at each position are:\n",
    "target = torch.tensor([[4, 0, 2]])   # shape [1, 3]\n",
    "\n",
    "print(\"target:\", target)\n",
    "target_unsq = target.unsqueeze(-1)\n",
    "print(\"target_unsq shape:\", target_unsq.shape)  # [1, 3, 1]\n",
    "\n",
    "tgt_logp = logp_tok.gather(-1, target_unsq)\n",
    "print(\"tgt_logp shape gather:\", tgt_logp.shape)  # [1, 3, 1]\n",
    "print(\"tgt_logp gather:\", tgt_logp)\n",
    "\n",
    "tgt_logp = tgt_logp.squeeze(-1)\n",
    "print(\"tgt_logp shape after squeeze:\", tgt_logp.shape)  # [1, 3]\n",
    "print(\"tgt_logp values:\", tgt_logp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23496120",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25457002",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "415d7821",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01466947",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "386c0b21",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "work-right-uae-dpo",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
